{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FLRP57ylUi"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "The objective is to create a **linear regression model** for a given dataset( House Sales in King County, USA). The overall idea of regression is to examine two things: (1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  (2) Which variables in particular are significant predictors of the outcome variable, and in what way do theyâ€“indicated by the magnitude and sign of the beta estimatesâ€“impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.\n",
        "\n",
        "**Linear Regression Analysis** consists of more than just fitting a linear line through a cloud of data points.  It consists of 3 stages â€“ (1) analyzing the correlation and directionality of the data, (2) estimating the model, i.e., fitting the line, and (3) evaluating the validity and usefulness of the model.\n",
        "\n",
        "## Regressions Performed\n",
        "\n",
        "\n",
        "**Simple Linear Regression:** <br>\n",
        "<br>\n",
        "1) 'bedrooms' vs 'price'<br>\n",
        "2) 'grade' vs 'price'<br>\n",
        "                         \n",
        "**Multiple Regression:** <br><br>\n",
        "1) 'bedrooms','grade', 'sqft_living', 'sqft_above'<br>\n",
        "2) 'bedrooms','bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'grade',                                     'sqft_above', 'sqft_basement', 'lat', 'sqft_living15'\n",
        "\n",
        "**Polynomial Regression:**<br>\n",
        "<br> 1) degree=2<br>\n",
        "2) degree=3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SJRI1OJylUk"
      },
      "source": [
        "# Data\n",
        "\n",
        "## Description\n",
        "\n",
        "In this dataset we have to predict the **sales price of houses in King County, Seattle**. It includes homes sold between May 2014 and May 2015. Before doing anything we should first know about the dataset what it contains what are its features and what is the structure of data.\n",
        "\n",
        "The dataset cantains 20 house features plus the price, along with 21613 observations.\n",
        "\n",
        "The description for the 20 features is given below:\n",
        "\n",
        "1. id :- It is the unique numeric number assigned to each house being sold.\n",
        "2. date :- It is the date on which the house was sold out.\n",
        "3. price:- It is the price of house which we have to predict so this is our target variable and aprat from it are our features.\n",
        "4. bedrooms :- It determines number of bedrooms in a house.\n",
        "5. bathrooms :- It determines number of bathrooms in a bedroom of a house.\n",
        "6. sqft_living :- It is the measurement variable which determines the measurement of house in square foot.\n",
        "7. sqft_lot : It is also the measurement variable which determines square foot of the lot.\n",
        "8. floors: It determines total floors means levels of house.\n",
        "9. waterfront : This feature determines whether a house has a view to waterfront 0 means no 1 means yes.\n",
        "10. view : This feature determines whether a house has been viewed or not 0 means no 1 means yes.\n",
        "11. condition : It determines the overall condition of a house on a scale of 1 to 5.\n",
        "12. grade : It determines the overall grade given to the housing unit, based on King County grading system on a scale of 1 to 11\n",
        "13. sqft_above : It determines square footage of house apart from basement.\n",
        "14. sqft_basement : It determines square footage of the basement of the house.\n",
        "15. yr_built : It detrmines the date of building of the house.\n",
        "16. yr_renovated : It detrmines year of renovation of house.\n",
        "17. zipcode : It determines the zipcode of the location of the house.\n",
        "18. lat : It determines the latitude of the location of the house.\n",
        "19. long : It determines the longitude of the location of the house.\n",
        "20. sqft_living15 : Living room area in 2015(implies-- some renovations)\n",
        "21. sqft_lot15 : lotSize area in 2015(implies-- some renovations)\n",
        "\n",
        "By observing the data, we can know that the **price is dependent on various features** like bedrooms(which is most dependent feature), bathrooms, sqft_living(second most important feature), sqft_lot, floors etc. The price is also dependent on the location of the house where it is present. The other features like waterfront, view are less dependent on the price. Of all the records, there are **no missing values, which helps us creating better model.**\n",
        "\n",
        "First, we **import** the required libraries like pandas, numpy, seaborn, matplotlib. Now import the **csv file.** Now we should get to know how the data is, what datatype using info function. We observe that date is in 'object' format. To know the no of rows and columns we use shape function. Describe the dataframe to know the mean, minumum, ,maximum, standard deviation, percentiles.\n",
        "\n",
        "Then plot graphs for visualization and then we do simple regression using 'bedrooms', multiple regression and polynomial regression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeXm4TcWrToB"
      },
      "source": [
        "## Import and initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "66mrBCvEylUl"
      },
      "outputs": [],
      "source": [
        "# importing numpy and pandas, seaborn\n",
        "\n",
        "import numpy as np\n",
        "# Numpy provides functionality for performing mathematical operations on arrays and matrices.\n",
        "# linear algebra\n",
        "\n",
        "import pandas as pd\n",
        "# The pandas provides data structures for efficiently storing and manipulating large datasets, as well as a wide range of functions for data cleaning, preparation, and analysis.\n",
        "# datapreprocessing, CSV file I/O\n",
        "\n",
        "import seaborn as sns\n",
        "# The seaborn provides a high-level interface for creating informative and attractive statistical graphics.\n",
        "# for plotting graphs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Matplotlib.pyplot is a collection of functions that provides a MATLAB-like plotting framework in Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixe6tbzI3Saw"
      },
      "source": [
        "Now import the data stored in the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xUhvJ4rylUl"
      },
      "outputs": [],
      "source": [
        "# The first method to read the scv file from Github.\n",
        "\n",
        "csvData = 'https://raw.githubusercontent.com/Yokhong/CIVL4210/main/H3_housing_price_regression/kc_house_data.csv'\n",
        "# We save the hyperlink of the data form Github.\n",
        "\n",
        "df = pd.read_csv(csvData)\n",
        "# And we directly copy the scv file from Github to random access memory (RAM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Z0FXJ4o-yg"
      },
      "source": [
        "Try to use another method by yourself!ðŸ˜Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Lrm4c3uV4xr"
      },
      "outputs": [],
      "source": [
        "# The second method to read the scv file from Github.ðŸ˜Š\n",
        "\n",
        "#import urllib.request as req\n",
        "# The urllib.request provides a set of functions for opening URLs (Uniform Resource Locators) and retrieving their contents.\n",
        "\n",
        "#url = 'https://raw.githubusercontent.com/Yokhong/CIVL4210/main/H3_housing_price_regression/kc_house_data.csv'\n",
        "# We save the hyperlink of the data form Github.\n",
        "\n",
        "#req.urlretrieve(url, \"/content/kc_house_data.csv\")\n",
        "#The urllib.request.urlretrieve is used to download a file from a URL and save it to a local directory.\n",
        "\n",
        "#file=\"kc_house_data.csv\" # relative address (computing)\n",
        "# Now, we can  see the scv file in the folder.\n",
        "\n",
        "#df = pd.read_csv(\"kc_house_data.csv\")\n",
        "# And we copy the scv file from Colab's folder to random access memory (RAM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUKBfN1wrjJg"
      },
      "source": [
        "## Check the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_Ixz6Z3aj5"
      },
      "source": [
        "Now we should get to know how the data is, what datatype using info function. We observe that date is in 'object' format. To know the no of rows and columns we use shape function. Describe the dataframe to know the mean, minumum, maximum, standard deviation, percentiles.\n",
        "\n",
        "Then plot graphs for visualization and then we do simple regression using 'bedrooms', multiple regression and polynomial regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qiePq8uylUm"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "# df.info() is used to print a concise summary of a DataFrame.\n",
        "# This method is useful for quickly examining the structure and contents of a DataFrame, including missing values and data types.\n",
        "# It can also be used to identify potential memory usage issues, as it shows the memory usage of the DataFrame.\n",
        "# When called on a DataFrame object df, df.info() outputs the following information:\n",
        "#  The number of rows and columns in the DataFrame\n",
        "#  The column names and their data types\n",
        "#  The number of non-null values in each column\n",
        "#  The memory usage of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FR1lmqpylUn"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "#df.head(16) # Try to change the number and find the difference with the default.ðŸ˜Š\n",
        "# The df.head() is used to display the first few rows of a DataFrame.\n",
        "# df.head() outputs the first 5 rows of the DataFrame by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYrnDlKKylUo"
      },
      "outputs": [],
      "source": [
        "#finding no of rows and columns\n",
        "\n",
        "df.shape\n",
        "# The df.shape returns a tuple representing the dimensions of a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H12_c4yylUo"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "# The df.isnull().sum() is used to count the number of missing values (null values) in each column of a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTqQVKJIylUo"
      },
      "outputs": [],
      "source": [
        "df['bedrooms'].value_counts()\n",
        "# The df[].value_counts() is used to count the number of occurrences of each unique value in a column of a DataFrame.\n",
        "# This method is useful for understanding the distribution of values in a column and for identifying the most common values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXZTYzhrqt0-"
      },
      "source": [
        "Try to use other labels and find out what happens.ðŸ˜Š\n",
        "\n",
        "<font size = \"6\">Question 1 (1 point): count the number of occurrences of each unique value in \"condition\"</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHQTzWsLrzm2"
      },
      "source": [
        "# Statistics and graphing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKTSWq7ZylUq"
      },
      "outputs": [],
      "source": [
        "fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\n",
        "# The plt.subplots() is used to create a new figure and one or more subplots.\n",
        "# fig is a variable that represents the entire figure, and axes is a variable that represents the subplot(s).\n",
        "# The subplots() method takes three arguments:\n",
        "# nrows: the number of rows of subplots to create (default is 1)\n",
        "# ncols: the number of columns of subplots to create (default is 1)\n",
        "# figsize: a tuple specifying the width and height of the figure in inches (default is (6.4, 4.8))\n",
        "\n",
        "plt.title('house prices by sqft_living')\n",
        "plt.xlabel('sqft_living')\n",
        "plt.ylabel('house prices')\n",
        "plt.legend()\n",
        "# The plt.legend() is used to add a legend to a plot.\n",
        "sns.barplot(x='sqft_living',y='price',data=df)\n",
        "# The sns.barplot() is used to create a bar plot.\n",
        "# data: the DataFrame containing the data to be plotted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvirQuLZylUq"
      },
      "outputs": [],
      "source": [
        "plt.hist('sqft_living',data=df,bins=5) # Try to use other labels and find out what happens.ðŸ˜Š\n",
        "# The plt.hist() is used to create a histogram.\n",
        "# bins: the number of bins to use in the histogram (default is 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vwo0Sr8IylUq"
      },
      "outputs": [],
      "source": [
        "fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\n",
        "sns.distplot(df['sqft_living'],hist=True,kde=True,rug=False,label='sqft_living',norm_hist=True)\n",
        "# The sns.distplot() is used to create a distribution plot.\n",
        "# hist: a boolean value indicating whether to show a histogram of the data (default is True)\n",
        "# kde: a boolean value indicating whether to show a kernel density estimate of the data (default is True)\n",
        "# rug: a boolean value indicating whether to show a rug plot of the data (default is False)\n",
        "# norm_hist: a boolean value indicating whether to normalize the histogram to a density plot (default is True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj0S_uzZylUq"
      },
      "outputs": [],
      "source": [
        "print('Mean',round(df['sqft_living'].mean(),2))\n",
        "# Printing the mean (average) value of the 'sqft_living' column\n",
        "# The value is rounded to two decimal places using the round() function.\n",
        "print('Median',df['sqft_living'].median())\n",
        "# Printing the median value of the 'sqft_living' column\n",
        "print('Mode',df['sqft_living'].mode()[0])\n",
        "# The mode() function is used to calculate the mode value of the dataset.\n",
        "# The [0] at the end of the line of code is used to select the first mode value from the list of mode values (if there are multiple mode values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AILQOvU3ylUr"
      },
      "outputs": [],
      "source": [
        "len(df[df['sqft_living']==1300])\n",
        "# Counting the number of instances where a specific value appears in a particular column of a DataFrame.\n",
        "# Mode 1300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u_dmHDY5v9p"
      },
      "source": [
        "<font size = \"6\">Question 2 (1 point): please draw a bar plot of 'house prices by sqft_above' and a density plot of 'sqft_above'</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jOuuAgn-qPc"
      },
      "source": [
        "<font size = \"6\">House Price Correlation Heatmap</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj_5WcoG-MHN"
      },
      "source": [
        "A house price correlation heatmap shows the relationships between different factors that can affect house prices, such as location, size, number of bedrooms, or amenities. It uses colors to indicate the strength and direction of these relationships: for example, dark colors might show a strong positive correlation, while lighter colors indicate weak or no correlation. This helps identify which factors are most related to house prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy29yx05-V3a"
      },
      "source": [
        "1. Variables Analyzed:\n",
        "\n",
        "  Common variables include square footage, number of bedrooms, bathrooms, age of the home, location, and features like pools or garages.\n",
        "\n",
        "2. Correlation Coefficient:\n",
        "\n",
        "  The heatmap uses a correlation coefficient (usually between -1 and 1) to show relationships:\n",
        "\n",
        "    1 means a perfect positive correlation (as one increases, the other does too).\n",
        "\n",
        "    -1 means a perfect negative correlation (as one increases, the other decreases).\n",
        "\n",
        "    0 means no correlation.\n",
        "\n",
        "3. Color Coding:\n",
        "\n",
        "  Different colors represent different levels of correlation. For example:\n",
        "\n",
        "    Darker colors may indicate stronger correlations.\n",
        "\n",
        "    Lighter colors may indicate weaker correlations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iem95UN-7oG"
      },
      "source": [
        "It helps real estate professionals and buyers understand which features most influence house prices. Buyers can use this information to make informed decisions about what features to prioritize.\n",
        "Sellers can understand what aspects of their home might increase its value.\n",
        "\n",
        "For example, if the heatmap shows a strong correlation between square footage and price, it suggests larger homes tend to sell for more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFAapsqBylUr"
      },
      "outputs": [],
      "source": [
        "def correlation_heatmap(df1):\n",
        "# Just define a function\n",
        "    _,ax=plt.subplots(figsize=(15,10))\n",
        "# The subplots() function returns two values: a Figure object and an Axes object. In this code, the Figure object is not needed, so it is assigned to the underscore symbol (_).\n",
        "    colormap=sns.diverging_palette(220,10,as_cmap=True)\n",
        "# The diverging_palette() function creates a color palette that varies smoothly between two specified colors.\n",
        "# The two colors are specified using the numbers 220 and 10, which correspond to hues on a color wheel.\n",
        "# The as_cmap parameter is set to True, which means that the resulting color palette will be returned as a matplotlib colormap object.\n",
        "    sns.heatmap(df.corr(numeric_only=True),annot=True,cmap=colormap)\n",
        "    #sns.heatmap(df.select_dtypes(np.number),annot=True,cmap=colormap)\n",
        "\n",
        "# Creating a heatmap plot using the Seaborn library.\n",
        "# The corr() function returns a matrix of pairwise correlations between columns of the DataFrame.\n",
        "# The 'annot' parameter is set to True, which means that the numeric values of the correlation coefficients will be displayed on the heatmap.\n",
        "\n",
        "correlation_heatmap(df)\n",
        "# Using this function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpAMP02GylUr"
      },
      "source": [
        "# Simple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g56LmElbylUr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# The train_test_split function is a commonly used function in machine learning that is used to split a dataset into two subsets: a training set and a testing set.\n",
        "\n",
        "from sklearn import linear_model\n",
        "# The linear_model module contains a variety of linear regression models that can be used for predictive modeling in machine learning.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# The KNeighborsRegressor model works by finding the k nearest neighbors to a given input in the training data, and then making a prediction based on the average value of the target variable for those neighbors.\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# The PolynomialFeatures class is a data preprocessing tool that can be used to create polynomial features from a set of input features.\n",
        "# Polynomial features are additional features that are created by raising the original features to a power, and then multiplying them together.\n",
        "# Creating polynomial features can be useful for improving the performance of machine learning models that assume a linear relationship between the input features and the target variable.\n",
        "# By including polynomial features, the model can capture more complex relationships between the input features and the target variable.\n",
        "\n",
        "from sklearn import metrics\n",
        "# These functions can be used to compare the predicted values of a model with the actual values, and to calculate various metrics that indicate how well the model is performing.\n",
        "# Some common metrics that are included in the metrics module include mean squared error (MSE), mean absolute error (MAE), R-squared (R2), and confusion matrix.\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "%matplotlib inline\n",
        "# This line enables the rendering of Matplotlib plots directly in the notebook interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9p4IuiuylUr"
      },
      "outputs": [],
      "source": [
        "train_data,test_data=train_test_split(df,train_size=0.8,random_state=3)\n",
        "# After class, you can try to change the number of 'train_size=0.8,random_state=3' and find out what happens.ðŸ˜Š\n",
        "# This line of code is using the train_test_split function to split 'df' into two subsets: a training set and a testing set.\n",
        "# The 'train_size' parameter is set to 0.8, which means that 80% of the data will be used for training the machine learning model, and 20% of the data will be used for testing the model.\n",
        "# The 'random_state' parameter is set to 3, which ensures that the split will be the same every time the code is run, allowing for reproducibility of the results.\n",
        "\n",
        "reg=linear_model.LinearRegression()\n",
        "# The LinearRegression class is a machine learning model that can be used for linear regression tasks, which involve predicting a continuous numerical value for a given input.\n",
        "# The model works by fitting a linear equation to the training data, where the coefficients of the equation represent the weights of the input features.\n",
        "\n",
        "x_train=np.array(train_data['sqft_living']).reshape(-1,1)\n",
        "y_train=np.array(train_data['price']).reshape(-1,1)\n",
        "# Try to use other labels and find out what happens.ðŸ˜Š\n",
        "# The np.array() function is used to convert the 'sqft_living' column to a NumPy array.\n",
        "# The reshape() method is then used to reshape the NumPy array into a 2-dimensional array with a single column and as many rows as there are data points in the 'sqft_living' column.\n",
        "# The '-1' parameter in the reshape() method is used to automatically determine the number of rows based on the size of the 'sqft_living' column.\n",
        "# Reshaping the NumPy array in this way is necessary because many machine learning models  expect the input data to be in a specific format.\n",
        "\n",
        "reg.fit(x_train,y_train)\n",
        "# The fit() method will use the training data to learn the coefficients of the regression model that best fits the data.\n",
        "# Once the model is fitted, it can be used to make predictions on new data.\n",
        "\n",
        "x_test=np.array(test_data['sqft_living']).reshape(-1,1)\n",
        "y_test=np.array(test_data['price']).reshape(-1,1)\n",
        "# Remember, if you change the label of training_data, please change the test_data into the same label.ðŸ˜Š\n",
        "# The .reshape(-1,1) method is used to reshape the array into a 2-dimensional array with only one column.\n",
        "# The -1 parameter in the method specifies that the number of rows should be inferred based on the length of the input array.\n",
        "# The resulting x_test array will have dimensions (n,1), where n is the number of rows in the 'sqft_living' column of test_data.\n",
        "\n",
        "pred=reg.predict(x_test)\n",
        "# This line uses a trained regression model reg to make predictions on a new set of data x_test.\n",
        "# The predicted values are based on the coefficients learned by the model during the training phase, and the input features in x_test.\n",
        "\n",
        "print('linear model')\n",
        "mean_squared_error=metrics.mean_squared_error(y_test,pred)\n",
        "# The mean_squared_error() function  takes two parameters: the true values y_test and the predicted values pred.\n",
        "# The function returns a single value, which is the average of the squared differences between the true and predicted values.\n",
        "\n",
        "print('Sqaured mean error', round(np.sqrt(mean_squared_error),2))\n",
        "# The np.sqrt() function calculates the square root of a given value.\n",
        "# The round() function is used to round the RMSE to two decimal places.\n",
        "\n",
        "print('R squared training',round(reg.score(x_train,y_train),3))\n",
        "print('R sqaured testing',round(reg.score(x_test,y_test),3) )\n",
        "# The score() method is used to calculate the R-squared value of the model.The R-squared value represents the proportion of the variance in the target variable that is explained by the independent variables in the model.\n",
        "# The R-squared value can range from 0 to 1, with higher values indicating better performance.\n",
        "# A value of 1 indicates that the model perfectly fits the data, while a value of 0 indicates that the model does not explain any of the variance in the target variable.\n",
        "\n",
        "print('intercept',reg.intercept_)\n",
        "# The intercept term is the value of the dependent variable when all independent variables are equal to zero.\n",
        "# In the context of linear regression, it represents the point where the regression line intersects the y-axis.\n",
        "\n",
        "print('coefficient',reg.coef_)\n",
        "# In the context of linear regression, the coefficients represent the change in the dependent variable for a unit change in the corresponding independent variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_N8KBCuylUr"
      },
      "outputs": [],
      "source": [
        "_, ax = plt.subplots(figsize= (12, 10))\n",
        "plt.scatter(x_test, y_test, color= 'darkgreen', label = 'data') # Try to change the color to pink or yellow.ðŸ˜Š\n",
        "# Create a scatter plot\n",
        "plt.plot(x_test, reg.predict(x_test), color='red', label= ' Predicted Regression line') # Try to change the color to pink or yellow.ðŸ˜Š\n",
        "# Draw the predicted regression line\n",
        "# Try to use other labels and find out what happens.ðŸ˜Š\n",
        "plt.xlabel('Living Space (sqft)')\n",
        "plt.ylabel('price')\n",
        "plt.legend()\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "# Set the visibility of the right spine (or edge) of the plot to False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vpjw6SMvBuu"
      },
      "source": [
        "<font size = \"6\">Question 3 (1 point): please draw a Simple Linear Regression plot of 'house prices by sqft_above'</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq57s5DXylUs"
      },
      "source": [
        "# Multiple Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple regression is a statistical technique used to understand the relationship between one dependent variable and two or more independent variables. It extends simple linear regression, which involves only one independent variable.\n",
        "\n",
        "<font size = 5> Key Features of Multiple Regression:</font>\n",
        "\n",
        "**Dependent Variable:**\n",
        "\n",
        "This is the outcome or the variable you want to predict (e.g., house price).\n",
        "\n",
        "**Independent Variables:**\n",
        "\n",
        "These are the predictors or factors that influence the dependent variable (e.g., square footage, number of bedrooms, location).\n",
        "\n",
        "The multiple regression equation can be expressed as:\n",
        "\n",
        "[ Y = b_0 + b_1X_1 + b_2X_2 + ... + b_nX_n + \\epsilon ]\n",
        "\n",
        "Where:\n",
        "\n",
        "(Y) is the dependent variable.\n",
        "\n",
        "(b_0) is the y-intercept.\n",
        "\n",
        "(b_1, b_2, ..., b_n) are the coefficients for the independent variables (X_1, X_2, ..., X_n).\n",
        "\n",
        "(\\epsilon) is the error term.\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "Linearity: The relationship between the dependent and independent variables is linear.\n",
        "\n",
        "Independence: Observations are independent of each other.\n",
        "\n",
        "Homoscedasticity: Constant variance of the error terms.\n",
        "\n",
        "Normality: The residuals (errors) are normally distributed.\n",
        "\n",
        "**Evaluation Metrics:**\n",
        "\n",
        "Common metrics to evaluate the model include R-squared, Adjusted R-squared, Mean Absolute Error (MAE), and Mean Squared Error (MSE)."
      ],
      "metadata": {
        "id": "68aB87Gswo8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size = 4.5>The following code uses Matplotlib and Seaborn libraries to draw box-and-line plots to visualize the relationship between different factors (e.g., house class, number of bedrooms, number of bathrooms) and price. The details are explained below:</font>"
      ],
      "metadata": {
        "id": "9G3GU-VezK8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size = 5>Components of a Box Plot:</font>\n",
        "\n",
        "**Box:**\n",
        "\n",
        "The central part of the box plot that represents the interquartile range (IQR), which contains the middle 50% of the data.\n",
        "\n",
        "The bottom of the box represents the first quartile (Q1, 25th percentile), and the top of the box represents the third quartile (Q3, 75th percentile).\n",
        "\n",
        "**Median Line:**\n",
        "\n",
        "A line inside the box that indicates the median (Q2, 50th percentile) of the dataset. It divides the box into two parts, showing where the middle of the data lies.\n",
        "\n",
        "**Whiskers:**\n",
        "\n",
        "Lines that extend from the top and bottom of the box to the highest and lowest values within 1.5 times the IQR from the quartiles.\n",
        "They help visualize the range of the data outside the IQR.\n",
        "\n",
        "**Outliers:**\n",
        "\n",
        "Data points that fall outside the whiskers (beyond 1.5 times the IQR). These are typically plotted as individual points or dots. Outliers indicate values that are significantly higher or lower than the rest of the data.\n",
        "\n",
        "**Axes:**\n",
        "\n",
        "The x-axis (horizontal) typically represents the categorical variable (e.g., groups or categories), while the y-axis (vertical) represents the numerical variable (e.g., values or measurements).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "**Box Height:** The height of the box shows the variability of the data. A taller box indicates greater variability, while a shorter box indicates less variability.\n",
        "\n",
        "**Median Position:** The position of the median line within the box indicates the skewness of the data. If the median is closer to the bottom, the data is positively skewed; if closer to the top, it is negatively skewed.\n",
        "\n",
        "**Outliers:** The presence of outliers can indicate variability in the data or potential anomalies that may require further investigation."
      ],
      "metadata": {
        "id": "DQ8fR9Y02WGu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZVISK0gylUs"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(2,1,figsize=(15,10))\n",
        "sns.boxplot(x=train_data['grade'],y=train_data['price'],ax=ax[0])\n",
        "sns.boxplot(x=train_data['bedrooms'],y=train_data['price'],ax=ax[1])\n",
        "_ , axes = plt.subplots(1, 1, figsize=(15,10))\n",
        "sns.boxplot(x=train_data['bathrooms'],y=train_data['price'])\n",
        "# Create a box plot using Seaborn library.\n",
        "# A box plot is a type of plot that displays the distribution of a dataset through their quartiles.\n",
        "# The box represents the interquartile range (IQR), which is the range between the 25th and 75th percentiles of the data.\n",
        "# The line inside the box represents the median value, and the whiskers extending from the box represent the range of the data, excluding the outliers.\n",
        "# Outliers are plotted as individual points beyond the whiskers.\n",
        "# The ax parameter specifies the subplot where the box plot will be plotted."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "complex_model 1"
      ],
      "metadata": {
        "id": "pFG45MdWCuiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phqnguotylUt"
      },
      "outputs": [],
      "source": [
        "features1=['bedrooms','grade','sqft_living','sqft_above'] # Features Selection\n",
        "reg=linear_model.LinearRegression() # Creating a linear regression model\n",
        "reg.fit(train_data[features1],train_data['price']) # Different from reg.fit(x_train,y_train), we use the train_data[features1].\n",
        "# A linear regression model is fitted using the features features1 and the target variable price from the training data.\n",
        "# Here train_data[features1] is the features data part.\n",
        "pred=reg.predict(test_data[features1])\n",
        "# Price predictions were made using the fitted model for the test data, which also used features1 as a feature.\n",
        "print('complex_model 1')\n",
        "mean_squared_error=metrics.mean_squared_error(y_test,pred)\n",
        "# Calculate the Root Mean Square Error (RMSE) between the predicted and actual test set prices.\n",
        "print('mean squared error(MSE)', round(np.sqrt(mean_squared_error),2))\n",
        "print('R squared training',round(reg.score(train_data[features1],train_data['price']),3))\n",
        "print('R squared training', round(reg.score(test_data[features1],test_data['price']),3))\n",
        "print('Intercept: ', reg.intercept_)\n",
        "print('Coefficient:', reg.coef_)\n",
        "# Print the intercept of the linear regression model and the coefficients of each feature;\n",
        "# these parameters indicate how the model predicts prices based on the input features."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "complex_model 2"
      ],
      "metadata": {
        "id": "KDLU_E7fCvnE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhPigm7lylUt"
      },
      "outputs": [],
      "source": [
        "features1 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','grade','sqft_above','sqft_basement','lat','sqft_living15']\n",
        "reg= linear_model.LinearRegression()\n",
        "reg.fit(train_data[features1],train_data['price'])\n",
        "pred = reg.predict(test_data[features1])\n",
        "print('Complex Model_2')\n",
        "mean_squared_error = metrics.mean_squared_error(y_test, pred)\n",
        "print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\n",
        "print('R-squared (training) ', round(reg.score(train_data[features1], train_data['price']), 3))\n",
        "print('R-squared (testing) ', round(reg.score(test_data[features1], test_data['price']), 3))\n",
        "print('Intercept: ', reg.intercept_)\n",
        "print('Coefficient:', reg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size = \"6\">Question 4 (1 point): what is the R-squared value on testing data in complex models?</font>\n",
        "\n",
        "<font size = \"6\">Question 5 (1 point): which model is the best among the above complex models? Why?</font>"
      ],
      "metadata": {
        "id": "iK6QzNDlBZM2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psK3XkSGylUt"
      },
      "source": [
        "# Polynomial Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "complex_model 3"
      ],
      "metadata": {
        "id": "hGnCJm4bCxBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuTdkFeQylUu"
      },
      "outputs": [],
      "source": [
        "polyfeat=PolynomialFeatures(degree=2)\n",
        "# PolynomialFeatures is a class that is used to generate a new set of features by raising the original features to a given degree.\n",
        "# In this case, the degree is set to 2, which means that the original features will be raised to the second power.(x^2)\n",
        "\n",
        "xtrain_poly=polyfeat.fit_transform(train_data[features1])\n",
        "xtest_poly=polyfeat.fit_transform(test_data[features1])\n",
        "# The fit_transform() transforms the original features in the training data into a new set of polynomial features.\n",
        "# The fit_transform() method first fits the polyfeat object to the training data to learn the parameters of the transformation.\n",
        "# and then, the fit_transform() applies the transformation to the training data to generate the new set of polynomial features.\n",
        "# The training data train_data[features1] and test data test_data[features1] are transformed using polynomial feature converter to generate polynomial features.\n",
        "poly=linear_model.LinearRegression()\n",
        "poly.fit(xtrain_poly,train_data['price'])\n",
        "polypred=poly.predict(xtest_poly)\n",
        "\n",
        "print('Complex Model_3')\n",
        "mean_squared_error = metrics.mean_squared_error(test_data['price'], polypred)\n",
        "print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\n",
        "print('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\n",
        "print('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "complex_model 4"
      ],
      "metadata": {
        "id": "1V4ObyF7CyPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQHqcJgyylUu"
      },
      "outputs": [],
      "source": [
        "polyfeat=PolynomialFeatures(degree=3)\n",
        "#  In this case, the degree is set to 3, which means that the original features will be raised to the third power.(x^3)\n",
        "\n",
        "xtrain_poly=polyfeat.fit_transform(train_data[features1])\n",
        "xtest_poly=polyfeat.fit_transform(test_data[features1])\n",
        "\n",
        "poly=linear_model.LinearRegression()\n",
        "poly.fit(xtrain_poly,train_data['price'])\n",
        "polypred=poly.predict(xtest_poly)\n",
        "\n",
        "print('complex model_4')\n",
        "mean_squared_error=metrics.mean_squared_error(test_data['price'],polypred)\n",
        "print('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\n",
        "print('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\n",
        "print('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}